{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "45c69a65-434c-422c-acce-4631f521804b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-03T11:29:35.445207Z",
     "iopub.status.busy": "2025-08-03T11:29:35.444907Z",
     "iopub.status.idle": "2025-08-03T11:29:35.449213Z",
     "shell.execute_reply": "2025-08-03T11:29:35.448389Z",
     "shell.execute_reply.started": "2025-08-03T11:29:35.445180Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir('./../')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f7836d72-252f-40fe-a76c-0aa69f77ab8e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-03T11:29:35.450143Z",
     "iopub.status.busy": "2025-08-03T11:29:35.449946Z",
     "iopub.status.idle": "2025-08-03T11:29:37.200351Z",
     "shell.execute_reply": "2025-08-03T11:29:37.199515Z",
     "shell.execute_reply.started": "2025-08-03T11:29:35.450127Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "from dataclasses import dataclass\n",
    "from autogen_core import AgentId, MessageContext, RoutedAgent, message_handler\n",
    "from autogen_agentchat.agents import AssistantAgent\n",
    "from autogen_agentchat.messages import TextMessage\n",
    "from autogen_ext.models.openai import OpenAIChatCompletionClient\n",
    "from autogen_ext.tools.langchain import LangChainToolAdapter\n",
    "from langchain_community.utilities import GoogleSerperAPIWrapper\n",
    "from langchain.agents import Tool\n",
    "from IPython.display import display, Markdown\n",
    "\n",
    "load_dotenv(override=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "91c47c46-b17f-4fa2-980c-4e7cbf27e243",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-03T11:29:37.202369Z",
     "iopub.status.busy": "2025-08-03T11:29:37.202025Z",
     "iopub.status.idle": "2025-08-03T11:29:37.206332Z",
     "shell.execute_reply": "2025-08-03T11:29:37.205031Z",
     "shell.execute_reply.started": "2025-08-03T11:29:37.202352Z"
    }
   },
   "outputs": [],
   "source": [
    "ALL_IN_ONE_WORKER = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "252e4b61-9e07-4512-8e49-033c6a468c6b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-03T11:29:37.207213Z",
     "iopub.status.busy": "2025-08-03T11:29:37.207004Z",
     "iopub.status.idle": "2025-08-03T11:29:37.215416Z",
     "shell.execute_reply": "2025-08-03T11:29:37.214474Z",
     "shell.execute_reply.started": "2025-08-03T11:29:37.207198Z"
    }
   },
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class Message:\n",
    "    content: str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "92539ca1-db9f-43ed-a559-90a0238d0f76",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-03T11:29:37.216340Z",
     "iopub.status.busy": "2025-08-03T11:29:37.216158Z",
     "iopub.status.idle": "2025-08-03T11:29:37.251312Z",
     "shell.execute_reply": "2025-08-03T11:29:37.250619Z",
     "shell.execute_reply.started": "2025-08-03T11:29:37.216325Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/somesh/PythonEnvs/P3.12_LLM/lib/python3.12/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.29.0 is exactly one major version older than the runtime version 6.31.1 at agent_worker.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "/home/somesh/PythonEnvs/P3.12_LLM/lib/python3.12/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.29.0 is exactly one major version older than the runtime version 6.31.1 at cloudevent.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from autogen_ext.runtimes.grpc import GrpcWorkerAgentRuntimeHost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "23ccca03-18e2-4b12-8a45-62bcdef851e3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-03T11:29:37.252184Z",
     "iopub.status.busy": "2025-08-03T11:29:37.252009Z",
     "iopub.status.idle": "2025-08-03T11:29:37.259478Z",
     "shell.execute_reply": "2025-08-03T11:29:37.258544Z",
     "shell.execute_reply.started": "2025-08-03T11:29:37.252170Z"
    }
   },
   "outputs": [],
   "source": [
    "host = GrpcWorkerAgentRuntimeHost(address=\"localhost:50051\")\n",
    "host.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "98eecb61-9cd7-48fb-beca-0412dbb386fa",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-03T11:29:37.260441Z",
     "iopub.status.busy": "2025-08-03T11:29:37.260237Z",
     "iopub.status.idle": "2025-08-03T11:29:37.266118Z",
     "shell.execute_reply": "2025-08-03T11:29:37.265162Z",
     "shell.execute_reply.started": "2025-08-03T11:29:37.260419Z"
    }
   },
   "outputs": [],
   "source": [
    "serper = GoogleSerperAPIWrapper()\n",
    "langchain_serper =Tool(name=\"internet_search\", func=serper.run, description=\"Useful for when you need to search the internet\")\n",
    "autogen_serper = LangChainToolAdapter(langchain_serper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "18f8034f-d377-4522-a4d1-50193cdeafa5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-03T11:29:37.267220Z",
     "iopub.status.busy": "2025-08-03T11:29:37.266924Z",
     "iopub.status.idle": "2025-08-03T11:29:37.272982Z",
     "shell.execute_reply": "2025-08-03T11:29:37.272093Z",
     "shell.execute_reply.started": "2025-08-03T11:29:37.267195Z"
    }
   },
   "outputs": [],
   "source": [
    "instruction1 = \"To help with a decision on whether to use AutoGen in a new AI Agent project, \\\n",
    "please research and briefly respond with reasons in favor of choosing AutoGen; the pros of AutoGen.\"\n",
    "\n",
    "instruction2 = \"To help with a decision on whether to use AutoGen in a new AI Agent project, \\\n",
    "please research and briefly respond with reasons against choosing AutoGen; the cons of Autogen.\"\n",
    "\n",
    "judge = \"You must make a decision on whether to use AutoGen for a project. \\\n",
    "Your research team has come up with the following reasons for and against. \\\n",
    "Based purely on the research from your team, please respond with your decision and brief rationale.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f91010be-1007-4f0d-a21a-4d2b3d952f24",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-03T11:29:37.273796Z",
     "iopub.status.busy": "2025-08-03T11:29:37.273583Z",
     "iopub.status.idle": "2025-08-03T11:29:37.279205Z",
     "shell.execute_reply": "2025-08-03T11:29:37.278465Z",
     "shell.execute_reply.started": "2025-08-03T11:29:37.273775Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_gemini_chat_client() -> OpenAIChatCompletionClient:\n",
    "    return OpenAIChatCompletionClient(model=Constants.GEMINI_MODEL_LITE,\n",
    "                                      api_key=os.getenv(Constants.GOOGLE_API_KEY),\n",
    "                                      model_info={'vision': True,\n",
    "                                                  'function_calling': True,\n",
    "                                                  'json_output': True,\n",
    "                                                  'family': ModelFamily.GEMINI_2_0_FLASH,\n",
    "                                                  'structured_output': True})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f39acdbc-57a5-4a14-b4c6-fb39dc954559",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-03T11:29:37.280007Z",
     "iopub.status.busy": "2025-08-03T11:29:37.279836Z",
     "iopub.status.idle": "2025-08-03T11:29:37.287579Z",
     "shell.execute_reply": "2025-08-03T11:29:37.286842Z",
     "shell.execute_reply.started": "2025-08-03T11:29:37.279994Z"
    }
   },
   "outputs": [],
   "source": [
    "class Player1Agent(RoutedAgent):\n",
    "    def __init__(self, name: str) -> None:\n",
    "        super().__init__(name)\n",
    "        model_client = get_gemini_chat_client()\n",
    "        self._delegate = AssistantAgent(name, model_client=model_client, tools=[autogen_serper], reflect_on_tool_use=True)\n",
    "\n",
    "    @message_handler\n",
    "    async def handle_my_message_type(self, message: Message, ctx: MessageContext) -> Message:\n",
    "        text_message = TextMessage(content=message.content, source=\"user\")\n",
    "        response = await self._delegate.on_messages([text_message], ctx.cancellation_token)\n",
    "        return Message(content=response.chat_message.content)\n",
    "    \n",
    "class Player2Agent(RoutedAgent):\n",
    "    def __init__(self, name: str) -> None:\n",
    "        super().__init__(name)\n",
    "        model_client = get_gemini_chat_client()\n",
    "        self._delegate = AssistantAgent(name, model_client=model_client, tools=[autogen_serper], reflect_on_tool_use=True)\n",
    "\n",
    "    @message_handler\n",
    "    async def handle_my_message_type(self, message: Message, ctx: MessageContext) -> Message:\n",
    "        text_message = TextMessage(content=message.content, source=\"user\")\n",
    "        response = await self._delegate.on_messages([text_message], ctx.cancellation_token)\n",
    "        return Message(content=response.chat_message.content)\n",
    "    \n",
    "class Judge(RoutedAgent):\n",
    "    def __init__(self, name: str) -> None:\n",
    "        super().__init__(name)\n",
    "        model_client = get_gemini_chat_client()\n",
    "        self._delegate = AssistantAgent(name, model_client=model_client)\n",
    "        \n",
    "    @message_handler\n",
    "    async def handle_my_message_type(self, message: Message, ctx: MessageContext) -> Message:\n",
    "        message1 = Message(content=instruction1)\n",
    "        message2 = Message(content=instruction2)\n",
    "        inner_1 = AgentId(\"player1\", \"default\")\n",
    "        inner_2 = AgentId(\"player2\", \"default\")\n",
    "        response1 = await self.send_message(message1, inner_1)\n",
    "        response2 = await self.send_message(message2, inner_2)\n",
    "        result = f\"## Pros of AutoGen:\\n{response1.content}\\n\\n## Cons of AutoGen:\\n{response2.content}\\n\\n\"\n",
    "        judgement = f\"{judge}\\n{result}Respond with your decision and brief explanation\"\n",
    "        message = TextMessage(content=judgement, source=\"user\")\n",
    "        response = await self._delegate.on_messages([message], ctx.cancellation_token)\n",
    "        return Message(content=result + \"\\n\\n## Decision:\\n\\n\" + response.chat_message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "882a63be-cc24-480e-851b-6bcdd8cc1276",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-03T11:29:37.288580Z",
     "iopub.status.busy": "2025-08-03T11:29:37.288385Z",
     "iopub.status.idle": "2025-08-03T11:29:37.294479Z",
     "shell.execute_reply": "2025-08-03T11:29:37.293768Z",
     "shell.execute_reply.started": "2025-08-03T11:29:37.288558Z"
    }
   },
   "outputs": [],
   "source": [
    "from autogen_ext.runtimes.grpc import GrpcWorkerAgentRuntime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0c416cdb-8abb-43b5-af6b-36f9527b5702",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-03T11:29:37.296467Z",
     "iopub.status.busy": "2025-08-03T11:29:37.296271Z",
     "iopub.status.idle": "2025-08-03T11:29:37.371952Z",
     "shell.execute_reply": "2025-08-03T11:29:37.371042Z",
     "shell.execute_reply.started": "2025-08-03T11:29:37.296452Z"
    }
   },
   "outputs": [],
   "source": [
    "if ALL_IN_ONE_WORKER:\n",
    "\n",
    "    worker = GrpcWorkerAgentRuntime(host_address=\"localhost:50051\")\n",
    "    await worker.start()\n",
    "\n",
    "    await Player1Agent.register(worker, \"player1\", lambda: Player1Agent(\"player1\"))\n",
    "    await Player2Agent.register(worker, \"player2\", lambda: Player2Agent(\"player2\"))\n",
    "    await Judge.register(worker, \"judge\", lambda: Judge(\"judge\"))\n",
    "\n",
    "    agent_id = AgentId(\"judge\", \"default\")\n",
    "\n",
    "else:\n",
    "\n",
    "    worker1 = GrpcWorkerAgentRuntime(host_address=\"localhost:50051\")\n",
    "    await worker1.start()\n",
    "    await Player1Agent.register(worker1, \"player1\", lambda: Player1Agent(\"player1\"))\n",
    "\n",
    "    worker2 = GrpcWorkerAgentRuntime(host_address=\"localhost:50051\")\n",
    "    await worker2.start()\n",
    "    await Player2Agent.register(worker2, \"player2\", lambda: Player2Agent(\"player2\"))\n",
    "\n",
    "    worker = GrpcWorkerAgentRuntime(host_address=\"localhost:50051\")\n",
    "    await worker.start()\n",
    "    await Judge.register(worker, \"judge\", lambda: Judge(\"judge\"))\n",
    "    agent_id = AgentId(\"judge\", \"default\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c6a7319-60b3-4bc7-a4ee-913e54b88972",
   "metadata": {
    "execution": {
     "execution_failed": "2025-08-03T11:46:09.670Z",
     "iopub.execute_input": "2025-08-03T11:29:37.372936Z",
     "iopub.status.busy": "2025-08-03T11:29:37.372712Z"
    }
   },
   "outputs": [],
   "source": [
    "response = await worker.send_message(Message(content=\"Go!\"), agent_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4d27eb7-603a-43ad-8e5c-851e7c672f79",
   "metadata": {
    "execution": {
     "execution_failed": "2025-08-03T11:46:09.672Z"
    }
   },
   "outputs": [],
   "source": [
    "display(Markdown(response.content))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
